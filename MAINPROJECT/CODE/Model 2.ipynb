{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
    "from keras.layers import Flatten, MaxPooling2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
    "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 536 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "training_set=train_data.flow_from_directory('Dataset/Train',target_size=(224,224),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 493 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data=ImageDataGenerator(rescale=1./255)\n",
    "test_set=test_data.flow_from_directory('Dataset/Test',target_size=(224,224),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 54, 54, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 17, 17, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 6, 6, 384)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 384)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              1052672   \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1000)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 6006      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,043,486\n",
      "Trainable params: 28,043,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Passing it to a Fully Connected layer\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# 3rd Fully Connected Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Output Layer\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"AlexNet.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, monitor='accuracy', verbose=1, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.8026 - accuracy: 0.3214\n",
      "Epoch 1: accuracy improved from -inf to 0.32143, saving model to AlexNet.h5\n",
      "16/16 [==============================] - 64s 4s/step - loss: 1.8026 - accuracy: 0.3214 - val_loss: 1.5942 - val_accuracy: 0.3979\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6147 - accuracy: 0.3810\n",
      "Epoch 2: accuracy improved from 0.32143 to 0.38095, saving model to AlexNet.h5\n",
      "16/16 [==============================] - 59s 4s/step - loss: 1.6147 - accuracy: 0.3810 - val_loss: 1.5814 - val_accuracy: 0.3958\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5927 - accuracy: 0.3869\n",
      "Epoch 3: accuracy improved from 0.38095 to 0.38690, saving model to AlexNet.h5\n",
      "16/16 [==============================] - 63s 4s/step - loss: 1.5927 - accuracy: 0.3869 - val_loss: 1.5770 - val_accuracy: 0.3917\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5764 - accuracy: 0.3906\n",
      "Epoch 4: accuracy improved from 0.38690 to 0.39062, saving model to AlexNet.h5\n",
      "16/16 [==============================] - 61s 4s/step - loss: 1.5764 - accuracy: 0.3906 - val_loss: 1.5715 - val_accuracy: 0.3917\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6013 - accuracy: 0.3869\n",
      "Epoch 5: accuracy did not improve from 0.39062\n",
      "16/16 [==============================] - 45s 3s/step - loss: 1.6013 - accuracy: 0.3869 - val_loss: 1.5814 - val_accuracy: 0.3896\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5800 - accuracy: 0.3926\n",
      "Epoch 6: accuracy improved from 0.39062 to 0.39258, saving model to AlexNet.h5\n",
      "16/16 [==============================] - 49s 3s/step - loss: 1.5800 - accuracy: 0.3926 - val_loss: 1.5790 - val_accuracy: 0.3938\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5927 - accuracy: 0.3810\n",
      "Epoch 7: accuracy did not improve from 0.39258\n",
      "16/16 [==============================] - 51s 3s/step - loss: 1.5927 - accuracy: 0.3810 - val_loss: 1.5857 - val_accuracy: 0.3833\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5804 - accuracy: 0.3929\n",
      "Epoch 8: accuracy improved from 0.39258 to 0.39286, saving model to AlexNet.h5\n",
      "16/16 [==============================] - 44s 3s/step - loss: 1.5804 - accuracy: 0.3929 - val_loss: 1.5611 - val_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5936 - accuracy: 0.3810\n",
      "Epoch 9: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 43s 3s/step - loss: 1.5936 - accuracy: 0.3810 - val_loss: 1.5637 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5836 - accuracy: 0.3849\n",
      "Epoch 10: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 43s 3s/step - loss: 1.5836 - accuracy: 0.3849 - val_loss: 1.5841 - val_accuracy: 0.3938\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6289 - accuracy: 0.3909\n",
      "Epoch 11: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 42s 3s/step - loss: 1.6289 - accuracy: 0.3909 - val_loss: 1.6034 - val_accuracy: 0.3958\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6039 - accuracy: 0.3869\n",
      "Epoch 12: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 43s 3s/step - loss: 1.6039 - accuracy: 0.3869 - val_loss: 1.5796 - val_accuracy: 0.3896\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5995 - accuracy: 0.3869\n",
      "Epoch 13: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 43s 3s/step - loss: 1.5995 - accuracy: 0.3869 - val_loss: 1.5730 - val_accuracy: 0.3958\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5866 - accuracy: 0.3829\n",
      "Epoch 14: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 42s 3s/step - loss: 1.5866 - accuracy: 0.3829 - val_loss: 1.5726 - val_accuracy: 0.3917\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5882 - accuracy: 0.3869\n",
      "Epoch 15: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 42s 3s/step - loss: 1.5882 - accuracy: 0.3869 - val_loss: 1.5790 - val_accuracy: 0.3896\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5866 - accuracy: 0.3889\n",
      "Epoch 16: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 36s 2s/step - loss: 1.5866 - accuracy: 0.3889 - val_loss: 1.5857 - val_accuracy: 0.3833\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5949 - accuracy: 0.3810\n",
      "Epoch 17: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 52s 3s/step - loss: 1.5949 - accuracy: 0.3810 - val_loss: 1.5715 - val_accuracy: 0.3979\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5906 - accuracy: 0.3849\n",
      "Epoch 18: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 55s 4s/step - loss: 1.5906 - accuracy: 0.3849 - val_loss: 1.5755 - val_accuracy: 0.3917\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5957 - accuracy: 0.3829\n",
      "Epoch 19: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 55s 4s/step - loss: 1.5957 - accuracy: 0.3829 - val_loss: 1.5806 - val_accuracy: 0.3896\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5928 - accuracy: 0.3867\n",
      "Epoch 20: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 56s 4s/step - loss: 1.5928 - accuracy: 0.3867 - val_loss: 1.5732 - val_accuracy: 0.3938\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5843 - accuracy: 0.3889\n",
      "Epoch 21: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 58s 4s/step - loss: 1.5843 - accuracy: 0.3889 - val_loss: 1.5696 - val_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6043 - accuracy: 0.3829\n",
      "Epoch 22: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 64s 4s/step - loss: 1.6043 - accuracy: 0.3829 - val_loss: 1.5848 - val_accuracy: 0.3938\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5858 - accuracy: 0.3889\n",
      "Epoch 23: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 58s 4s/step - loss: 1.5858 - accuracy: 0.3889 - val_loss: 1.5776 - val_accuracy: 0.3938\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5965 - accuracy: 0.3849\n",
      "Epoch 24: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 59s 4s/step - loss: 1.5965 - accuracy: 0.3849 - val_loss: 1.5711 - val_accuracy: 0.3938\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5800 - accuracy: 0.3849\n",
      "Epoch 25: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 57s 4s/step - loss: 1.5800 - accuracy: 0.3849 - val_loss: 1.5773 - val_accuracy: 0.3896\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5840 - accuracy: 0.3849\n",
      "Epoch 26: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 58s 4s/step - loss: 1.5840 - accuracy: 0.3849 - val_loss: 1.5750 - val_accuracy: 0.3938\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5848 - accuracy: 0.3909\n",
      "Epoch 27: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 59s 4s/step - loss: 1.5848 - accuracy: 0.3909 - val_loss: 1.5728 - val_accuracy: 0.3938\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5831 - accuracy: 0.3909\n",
      "Epoch 28: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 58s 4s/step - loss: 1.5831 - accuracy: 0.3909 - val_loss: 1.5737 - val_accuracy: 0.3917\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5973 - accuracy: 0.3829\n",
      "Epoch 29: accuracy did not improve from 0.39286\n",
      "16/16 [==============================] - 58s 4s/step - loss: 1.5973 - accuracy: 0.3829 - val_loss: 1.5752 - val_accuracy: 0.3958\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5901 - accuracy: 0.3790\n",
      "Epoch 30: accuracy did not improve from 0.39286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 56s 4s/step - loss: 1.5901 - accuracy: 0.3790 - val_loss: 1.5752 - val_accuracy: 0.3917\n",
      "Epoch 31/100\n",
      "15/16 [===========================>..] - ETA: 1s - loss: 1.5828 - accuracy: 0.3938"
     ]
    }
   ],
   "source": [
    "#### Fitting the model\n",
    "history = model.fit(\n",
    "           training_set, steps_per_epoch=training_set.samples // batch_size, \n",
    "           epochs=epochs, \n",
    "           validation_data=test_set,validation_steps=test_set.samples // batch_size,\n",
    "           callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def graph():\n",
    "    #Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "graph()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs():\n",
    "# Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
