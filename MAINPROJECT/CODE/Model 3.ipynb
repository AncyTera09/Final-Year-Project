{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 536 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "training_set=train_datagen.flow_from_directory('Dataset/Train',target_size=(224,224),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 493 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_set=test_datagen.flow_from_directory('dataset/Test',target_size=(224,224),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 74, 74, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 37, 37, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 128)       36992     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1179904   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,219,334\n",
      "Trainable params: 1,219,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Classifier=Sequential()\n",
    "Classifier.add(Convolution2D(32,3,3,input_shape=(224,224,3),activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "Classifier.add(Convolution2D(128,3,3,activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "Classifier.add(Flatten())\n",
    "Classifier.add(Dense(256, activation='relu'))\n",
    "Classifier.add(Dense(6, activation='softmax'))\n",
    "\n",
    "Classifier.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "Classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"LeNet.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, monitor='accuracy', verbose=1, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 120\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6340 - accuracy: 0.3671\n",
      "Epoch 1: accuracy improved from -inf to 0.36706, saving model to LeNet.h5\n",
      "16/16 [==============================] - 54s 3s/step - loss: 1.6340 - accuracy: 0.3671 - val_loss: 1.5413 - val_accuracy: 0.4000\n",
      "Epoch 2/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 0.4127\n",
      "Epoch 2: accuracy improved from 0.36706 to 0.41270, saving model to LeNet.h5\n",
      "16/16 [==============================] - 41s 3s/step - loss: 1.5255 - accuracy: 0.4127 - val_loss: 1.4541 - val_accuracy: 0.4313\n",
      "Epoch 3/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4953 - accuracy: 0.3730\n",
      "Epoch 3: accuracy did not improve from 0.41270\n",
      "16/16 [==============================] - 44s 3s/step - loss: 1.4953 - accuracy: 0.3730 - val_loss: 1.5919 - val_accuracy: 0.3167\n",
      "Epoch 4/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4464 - accuracy: 0.4246\n",
      "Epoch 4: accuracy improved from 0.41270 to 0.42460, saving model to LeNet.h5\n",
      "16/16 [==============================] - 41s 3s/step - loss: 1.4464 - accuracy: 0.4246 - val_loss: 1.3572 - val_accuracy: 0.5021\n",
      "Epoch 5/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3769 - accuracy: 0.4802\n",
      "Epoch 5: accuracy improved from 0.42460 to 0.48016, saving model to LeNet.h5\n",
      "16/16 [==============================] - 43s 3s/step - loss: 1.3769 - accuracy: 0.4802 - val_loss: 1.3180 - val_accuracy: 0.4854\n",
      "Epoch 6/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3553 - accuracy: 0.4762\n",
      "Epoch 6: accuracy did not improve from 0.48016\n",
      "16/16 [==============================] - 41s 3s/step - loss: 1.3553 - accuracy: 0.4762 - val_loss: 1.2335 - val_accuracy: 0.5458\n",
      "Epoch 7/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2761 - accuracy: 0.5139\n",
      "Epoch 7: accuracy improved from 0.48016 to 0.51389, saving model to LeNet.h5\n",
      "16/16 [==============================] - 43s 3s/step - loss: 1.2761 - accuracy: 0.5139 - val_loss: 1.2091 - val_accuracy: 0.5333\n",
      "Epoch 8/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2821 - accuracy: 0.5298\n",
      "Epoch 8: accuracy improved from 0.51389 to 0.52976, saving model to LeNet.h5\n",
      "16/16 [==============================] - 40s 3s/step - loss: 1.2821 - accuracy: 0.5298 - val_loss: 1.1765 - val_accuracy: 0.5542\n",
      "Epoch 9/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1910 - accuracy: 0.5496\n",
      "Epoch 9: accuracy improved from 0.52976 to 0.54960, saving model to LeNet.h5\n",
      "16/16 [==============================] - 40s 3s/step - loss: 1.1910 - accuracy: 0.5496 - val_loss: 1.0940 - val_accuracy: 0.5938\n",
      "Epoch 10/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1392 - accuracy: 0.5615\n",
      "Epoch 10: accuracy improved from 0.54960 to 0.56151, saving model to LeNet.h5\n",
      "16/16 [==============================] - 38s 2s/step - loss: 1.1392 - accuracy: 0.5615 - val_loss: 1.0392 - val_accuracy: 0.6167\n",
      "Epoch 11/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1525 - accuracy: 0.5655\n",
      "Epoch 11: accuracy improved from 0.56151 to 0.56548, saving model to LeNet.h5\n",
      "16/16 [==============================] - 55s 4s/step - loss: 1.1525 - accuracy: 0.5655 - val_loss: 1.0481 - val_accuracy: 0.5833\n",
      "Epoch 12/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1341 - accuracy: 0.5536\n",
      "Epoch 12: accuracy did not improve from 0.56548\n",
      "16/16 [==============================] - 54s 4s/step - loss: 1.1341 - accuracy: 0.5536 - val_loss: 1.0867 - val_accuracy: 0.5562\n",
      "Epoch 13/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1042 - accuracy: 0.5853\n",
      "Epoch 13: accuracy improved from 0.56548 to 0.58532, saving model to LeNet.h5\n",
      "16/16 [==============================] - 54s 3s/step - loss: 1.1042 - accuracy: 0.5853 - val_loss: 0.9759 - val_accuracy: 0.6104\n",
      "Epoch 14/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0354 - accuracy: 0.5933\n",
      "Epoch 14: accuracy improved from 0.58532 to 0.59325, saving model to LeNet.h5\n",
      "16/16 [==============================] - 57s 4s/step - loss: 1.0354 - accuracy: 0.5933 - val_loss: 1.0843 - val_accuracy: 0.5667\n",
      "Epoch 15/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9810 - accuracy: 0.6349\n",
      "Epoch 15: accuracy improved from 0.59325 to 0.63492, saving model to LeNet.h5\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.9810 - accuracy: 0.6349 - val_loss: 0.9192 - val_accuracy: 0.6354\n",
      "Epoch 16/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9708 - accuracy: 0.6429\n",
      "Epoch 16: accuracy improved from 0.63492 to 0.64286, saving model to LeNet.h5\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.9708 - accuracy: 0.6429 - val_loss: 0.9509 - val_accuracy: 0.6583\n",
      "Epoch 17/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0162 - accuracy: 0.6071\n",
      "Epoch 17: accuracy did not improve from 0.64286\n",
      "16/16 [==============================] - 58s 4s/step - loss: 1.0162 - accuracy: 0.6071 - val_loss: 0.8431 - val_accuracy: 0.6854\n",
      "Epoch 18/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9384 - accuracy: 0.6290\n",
      "Epoch 18: accuracy did not improve from 0.64286\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.9384 - accuracy: 0.6290 - val_loss: 0.7836 - val_accuracy: 0.7000\n",
      "Epoch 19/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.7123\n",
      "Epoch 19: accuracy improved from 0.64286 to 0.71230, saving model to LeNet.h5\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.8270 - accuracy: 0.7123 - val_loss: 0.7169 - val_accuracy: 0.7458\n",
      "Epoch 20/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8578 - accuracy: 0.6806\n",
      "Epoch 20: accuracy did not improve from 0.71230\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.8578 - accuracy: 0.6806 - val_loss: 0.7326 - val_accuracy: 0.7188\n",
      "Epoch 21/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8403 - accuracy: 0.6825\n",
      "Epoch 21: accuracy did not improve from 0.71230\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.8403 - accuracy: 0.6825 - val_loss: 0.6744 - val_accuracy: 0.7521\n",
      "Epoch 22/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7839 - accuracy: 0.7070\n",
      "Epoch 22: accuracy did not improve from 0.71230\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.7839 - accuracy: 0.7070 - val_loss: 0.7844 - val_accuracy: 0.7042\n",
      "Epoch 23/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8494 - accuracy: 0.6825\n",
      "Epoch 23: accuracy did not improve from 0.71230\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.8494 - accuracy: 0.6825 - val_loss: 0.6094 - val_accuracy: 0.7958\n",
      "Epoch 24/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7355 - accuracy: 0.7401\n",
      "Epoch 24: accuracy improved from 0.71230 to 0.74008, saving model to LeNet.h5\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.7355 - accuracy: 0.7401 - val_loss: 0.6054 - val_accuracy: 0.7979\n",
      "Epoch 25/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6480 - accuracy: 0.7738\n",
      "Epoch 25: accuracy improved from 0.74008 to 0.77381, saving model to LeNet.h5\n",
      "16/16 [==============================] - 49s 3s/step - loss: 0.6480 - accuracy: 0.7738 - val_loss: 0.6250 - val_accuracy: 0.7646\n",
      "Epoch 26/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6504 - accuracy: 0.7698"
     ]
    }
   ],
   "source": [
    "#### Fitting the model\n",
    "history = Classifier.fit(\n",
    "           training_set, steps_per_epoch=training_set.samples // batch_size, \n",
    "           epochs=epochs, \n",
    "           validation_data=test_set,validation_steps=test_set.samples // batch_size,\n",
    "           callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "for i in range(epochs):\n",
    "    if i%5 == 0:\n",
    "        plt.annotate(np.round(history.history['accuracy'][i]*100,2),xy=(i,history.history['accuracy'][i]))\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "for i in range(epochs):\n",
    "    if i%5 == 0:\n",
    "        plt.annotate(np.round(history.history['loss'][i]*100,2),xy=(i,history.history['loss'][i]))\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
